       ECON 57: Economic Statistics - R Programming
                         Lab 2
                              Augusto Gonzalez Bonorino
                                     October 12, 2023

           The labs in ECON 57: Economic Statistics are designed to solidify your
       comprehension of course concepts while fostering problem-solving skills. By en-
       gaging in hands-on coding exercises, you’ll reinforce your understanding of vari-
       ables, data types, conditionals, and more. As exercises progressively increase
       in complexity, you’ll develop the analytical mindset required for addressing in-
       tricate economic questions. These labs also encourage independent learning by
       introducing concepts not yet covered in class. Utilizing external resources like
       Google, Stack Overflow, or ChatGPT mirrors real-world problem-solving sce-
       narios, empowering you to effectively apply your existing knowledge. Embrace
       these challenges as opportunities to grow, both in coding prowess and in your
       grasp of the dynamic relationship between statistics and economics.
           Most of these exercises can be solved with chatGPT. I encourage you to take
       the hard route and first give them a genuine try yourself, utilizing chatGPT as
       an assistant to help you brainstorm, fix bugs or test ideas instead of having it
       do all the work for you.



           Submission guidelines: All of your work should be done in an R note-
       book. Create an R notebook in Rstudio and name it with the following format
       ”firstName lastName Lab2.rmd”. Write your solutions in separate code cells
       (these are the gray boxes encompassed by “‘r and “‘), include the instruction
       for that exercise, and use markdown to format the notebook. This lab is due
       Friday October 13 at 11:59pm.



Exercise 1: (Exploratory Data Analysis with ggplot2)
            In this exercise, you will explore the mtcars dataset, a built-in dataset in
            R, using ggplot2. For this exercise, focus on your analysis and usage of
            visualizations as statistical tools. Don’t worry much about customizing
            the chart. Here are the steps to follow:

               • Load Libraries and Dataset:


                                              1
                   – Load the ggplot2 library.
                   – Load the mtcars dataset.
               • Create a scatter plot to visualize the relationship between ”mpg”
                 (miles per gallon) on the x-axis and ”hp” (horsepower) on the y-axis.
               • Create bar charts for the following discrete variables: ”cyl” (number
                 of cylinders), and ”gear” (number of forward gears). The bar charts
                 must be superimposed in one single canvas, not three separate bar
                 charts. How many cars have 8 cylinders? How many have 4? What
                 is the median and average number of gears?
               • Calculate the covariance and correlation between ”mpg” and ”hp” to
                 validate your visual insights.
               • Write a brief summary of your findings, including any observed pat-
                 terns or relationships from the visualizations. Discuss the implica-
                 tions of covariance and correlation in the context of your analysis.

Exercise 2: (Advanced ggplot2 Visualizations)
            In this exercise, you will continue to work with the mtcars dataset. Here’s
            how to proceed:

               • Create three line plots on a single ggplot canvas, representing ”mpg,”
                 ”hp,” and ”qsec” (quarter-mile time) on a common x-axis.
               • Include a legend, axis labels, and customize the appearance of the
                 lines (e.g., colors, line types).
               • Add a title and additional details to enhance the informativeness of
                 the chart.
               • Write an explanation highlighting the significance of the chart, iden-
                 tifying any trends or insights, and discussing the story it conveys
                 based on the data.

Exercise 3: (Data Manipulation with Base R and dplyr)
            For this exercise, you will practice data manipulation using both base R
            and dplyr with the mtcars dataset. The main focus here is to master
            base R operations for manipulating data and finding the appropiate dplyr
            function to perform the same operation. Follow these steps:

               • Using base R, select rows where ”mpg” is greater than 20 and filter
                 the dataset accordingly.
               • Add a new column named ”disp mpg ratio,” which is the ratio of
                 ”disp” (displacement) to ”mpg.” Hint: You will need to compute this
                 ratio. Remember that operations between vectors are ”vectorized”.
               • Using dplyr, perform the same filtering operation (select rows where
                 ”mpg” is greater than 20) and add the ”disp mpg ratio” column.


                                              2
               • Research and implement the following dplyr functions: ’summarise’,
                 ’slice sample’ and ’rename’. Think how you could apply these on the
                 mtcars dataset and provide at least one example use case of each
                 function.

Exercise 4: (Custom Statistical Analysis)
            In this final exercise, you will conduct a comprehensive Exploratory Data
            Analysis (EDA) on a custom dataset of your choice. The goal is to un-
            derstand and analyze the data, discover patterns, and gain insights that
            can inform further statistical analysis or decision-making. This exercise
            will help you develop a solid foundation in data exploration, visualization,
            and interpretation, which are essential skills in economics and statistics.
            As you evolve as a statistician throughout this class, leading up to your
            final project, you will start to write more formal analyses. This means
            that all of your code must be accompanied by some explanation of what
            the code is doing. Don’t explain how to write the R code, but why did you
            choose to write that code. For example, you will write code for visualizing
            data, why did you choose that visualization? What insight does it help
            you (and the reader) gain? If you manipulate your data by adding columns
            or filtering rows, why did you decide to do that? In general, get used to
            articulating your reasoning behind the code you are writing. This will
            help you write better code, double check your implementation, and help
            the reader of your analysis grasp the information better.
            Follow the following step-by-step methodology to conduct your EDA. Note
            some of the steps noted in this process might not be relevant for your par-
            ticular analysis, but may help you structure your strategy to conducting
            this analysis.

               • Step 1: Data Collection and Understanding
                 (a) Find and download a dataset (related or not to economics) from
                     a reliable source. Note that I am asking for a dataset and not
                     just a variable, therefore if you stick with the sources we have
                     been working with (FRED, IMF, etc). This means that you will
                     need to download a few files and put them all together into one
                     spreadsheet; or you can load them individually to R and then add
                     them as columns to a dataframe. Alternatively, pick a dataset
                     from, say Kaggle, that already has many variables/columns
                 (b) Load the data to Rstudio.
               • Step 2: Data Cleaning and Preprocessing
                 (a) Check for missing values and decide how to handle them (e.g.,
                     remove, impute). We only covered the simple approach of ig-
                     noring/removing missing values (i.e., NA values). What are the
                     implications of simply ignoring missing observations? What is
                     an alternative approach we might want to consider?


                                              3
     (b) Examine data types and ensure they are appropriate for analysis
         (i.e., what you expect to be a numeric variable is actually numeric
         and not a character for example). Hint: There are both base R
         and dplyr functions you can leverage for this.
     (c) Rename variables or columns with meaningful names if necessary.
     (d) Filter rows and/or select relevant columns based on the analysis’
         objectives.
  • Step 3: Data Visualization
     (a) Create a variety of meaningful visualizations (e.g., scatter plots,
         bar charts, line charts) to explore relationships between variables.
     (b) Use ggplot2 for customized and informative plots.
     (c) Include labels, titles, and legends to enhance interpretability.
  • Step 4: Descriptive Statistics
     (a) Calculate and summarize key descriptive statistics for numeric
         variables (e.g., mean, median, standard deviation).
     (b) Generate summary statistics or frequency tables for categorical
         variables.
     (c) Visualize the distribution of variables using histograms, box plots,
         or bar charts.
  • Step 5: Insights and Conclusion
     (a) Summarize the main insights and findings from your EDA pro-
         cess.
     (b) Discuss any implications, real-world applications, or policy rec-
         ommendations that can be derived from your analysis. In short,
         what can we learn from all your EDA work?
     (c) Reflect on the EDA process, challenges faced, and lessons learned.
         Make special note to the methodology you followed. Does it make
         sense to you that we should start by exploring our data visually?
         Do you prefer to look at numbers first? The given methodology
         reflects my practice and preferences, but there is no rule on how
         to do this. Read a little bit about best practices for EDA and
         provide your opinion.

By following this comprehensive EDA methodology, you will gain valuable
experience in data analysis and learn a structured approach that can be
applied to future statistical analyses in your academic or professional en-
deavors. Hopefully this methodology can serve as a recipe for your future
work.




                                  4
