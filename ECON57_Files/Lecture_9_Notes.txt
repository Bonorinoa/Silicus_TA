Lecture Notes for ECON 57: Economic Statistics - Lecture 9

Introduction
Brief overview of today's topics.
Emphasize the importance of understanding probability distributions in economics and data science.



Brief Recap of Random Variables, PMF/PDF, CDF, Expected Value, and Variance
Random Variables: Define and differentiate between discrete and continuous.
PMF/PDF: Explain the difference and the idea of probability mass vs. density.
CDF: Introduce as a cumulative measure of probability.
Expected Value: Average or mean value of a random variable.
Variance: Measure of the spread or dispersion.



Notable Probability Distributions
Binomial: Discrete distribution, number of successes in a fixed number of trials.
Poisson: Discrete, number of events in a fixed interval of time or space.
Bernoulli: Discrete, success or failure.
Uniform: Continuous, equal probability over a range.
Normal: Continuous, bell-shaped curve.



Importance of the Normal Gaussian Distribution
Historical Context: Introduced by Gauss, used in astronomy.
Properties: Bell-shaped, symmetric, mean, and variance.
Applications: Stock returns, economic indicators, consumer behavior.



Central Limit Theorem (CLT)
Definition: Sample means of large samples are approximately normally distributed.
Visualization: Show the distribution of sample means from a non-normal distribution.
Key Takeaway: No matter the shape of the original distribution, when we take many samples and average them, the resulting distribution of those averages tends to look like a bell curve.
Real-world Analogy: Imagine measuring the heights of a group of people in different cities. Each city might have its unique distribution, but if you average the heights from each city and plot those averages, the resulting distribution will be approximately normal.


Law of Large Numbers (LLN)
Definition: Sample mean converges to the population mean as sample size increases.
Visualization: Show the running average of a coin toss.
Key Takeaway: As we collect more data, our sample average gets closer and closer to the true average (or expected value).
Difference from CLT: Focus on convergence to a true value vs. distribution shape.
Real-world Analogy: If you were to estimate the average height of people in a city by measuring a few individuals, your estimate might be off. But as you measure more and more people, your estimate will get closer to the true average height of the city's population.


Modeling the Real World with Notable Distributions
Binomial: Sales pitches, poker hands, ad clicks.
Poisson: Product defects, card combinations, website visits.
Bernoulli: Market movements, poker strategies, purchase decisions.
Uniform: Random draws, card draws, random simulations.
Normal: Income distributions, poker winnings, standardized data in ML.



Limitations of Probability Distributions
Assumptions: Ensure data meets distribution assumptions.
Real-World Complexity: Distributions are simplifications.
Over-reliance: Consider multiple models.
Data Quality: Ensure data is accurate and relevant.


Historical Context of the Gaussian Distribution:

Origins: The normal distribution has been studied for centuries, but its formal introduction is credited to the German mathematician Carl Friedrich Gauss in the early 19th century. Hence, it's often referred to as the "Gaussian distribution."
Astronomy & Measurement Errors: Gauss introduced the normal distribution while analyzing astronomical data. He was trying to model the errors in his measurements (small deviations from the true value). Gauss posited that these errors were the result of numerous small effects, which when summed up, produced a bell-shaped curve.
Further Development: The French mathematician Pierre-Simon Laplace independently developed the central limit theorem, which underpins the importance of the normal distribution in statistics. The theorem states that the sum of many independent and identically distributed random variables tends to be normally distributed, regardless of the original distribution of the variables.
Widespread Application: Over time, the normal distribution was found to describe a wide variety of phenomena, from biological traits (like height) to economic indicators. Its mathematical properties made it convenient for analysis, and its ubiquity in nature made it a cornerstone of statistical theory.
Modern Usage: Today, the normal distribution is foundational in both theoretical and applied statistics. It's used in hypothesis testing, confidence intervals, and many other statistical methods. Moreover, the concepts of the mean and standard deviation, central to the normal distribution, are fundamental in many fields of science.


Sure, I can help with that. This is a problem of statistics, specifically it's about the normal distribution. Here are the steps to solve it:

1. **Identify the parameters of the normal distribution**: In this case, the average income (mean, μ) is $50,000 and the standard deviation (σ) is $10,000.

2. **Standardize the values**: We need to convert the values $40,000 and $60,000 into z-scores. The z-score is calculated as follows:

    $$z = \frac{x - μ}{σ}$$

    where x is the value we want to standardize.

    For $40,000:

    $$z_{40} = \frac{40000 - 50000}{10000} = -1$$

    For $60,000:

    $$z_{60} = \frac{60000 - 50000}{10000} = 1$$

3. **Find the probability**: We want to find P(-1 < Z < 1). According to the standard normal distribution table (also known as the Z-table), the probability that Z is less than 1 is approximately 0.8413 and the probability that Z is less than -1 is approximately 0.1587.

4. **Calculate the probability of earning between $40,000 and $60,000**: Subtract the two probabilities:

    $$P(-1 < Z < 1) = P(Z < 1) - P(Z < -1) = 0.8413 - 0.1587 = 0.6826$$

So, approximately 68.26% of people in this city earn between $40,000 and $60,000.

